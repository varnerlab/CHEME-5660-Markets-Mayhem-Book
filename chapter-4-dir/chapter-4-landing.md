# Rational Decision Making
Making decisions in uncertain situations, potentially involving multiple agents, can be challenging. Decision-making in uncertain situations involves uncertainty and risk. Thus, in this unit, we'll introduce tools to model uncertainty, approaches to understand risk, and risk tolerance and model the actions of multiple actors involved in our decisions.

```{topic} Decision Making Outline
In this unit, we will discuss the following topics:

* [Expected utility hypothesis](./expected-utility.md) is a cornerstone concept in decision theory and economics. It proposes that individuals make choices based on their anticipated outcomes and corresponding utility or satisfaction. This hypothesis assumes that individuals are rational and seek to maximize their expected utility when making decisions, subject to various constraints.

* [The Markov property and Markov processes](./markov.md) are mathematical models of randomness that assume the next state of a sysyem depends only on the current state and not the past. It's like a game where the outcome of the next move depends only on the gameâ€™s current state, not on previous states. Markov processes have many applications, such as predicting the weather, modeling financial markets, and understanding how diseases spread. We'll make use of Markov processes to model the evolution of sequential decision making, i.e., [Markov decision processes](./markov/mdp.md). 

* [Reinforcement learning](./rl.md) is a type of machine learning where an algorithm learns to make decisions by trial and error, much like a human learns through experience. Reinforcement learning involves an agent interacting with an environment and receiving rewards or punishments for its actions, which helps it to learn which actions lead to desirable outcomes. Reinforcement learning has many applications, such as teaching robots to perform complex tasks, optimizing business decisions, and even playing games. In this unit, we'll explore reinforcement learning and its applications in finance.

```