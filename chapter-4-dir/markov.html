

<!DOCTYPE html>


<html >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Markov Chains &#8212; CHEME 5660</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/myfile.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-PG1Y6R28LY"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-PG1Y6R28LY');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'chapter-4-dir/markov';</script>
    <link rel="canonical" href="https://varnerlab.github.io/CHEME-5660-Markets-Mayhem-Book/infrastructure.html/chapter-4-dir/markov.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Stochastic Sequential Decision Making" href="mdp.html" />
    <link rel="prev" title="Unit 4: Decisions" href="chapter-4-landing.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="None"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../infrastructure.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/cornell_seal_simple_black-164.svg" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/cornell_seal_simple_black-164.svg" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../infrastructure.html">
                    CHEME 5660: Financial Data, Markets, and Mayhem
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter-1-dir/chapter-1-landing.html">Unit 1. Financial Basics</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter-1-dir/pfinance-basics.html">Personal Finance Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter-1-dir/assets.html">Financial Balances and Abstract Assets</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter-2-dir/chapter-2-landing.html">Unit 2. Wealth Creation</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter-2-dir/bonds.html">Fixed Income Debt Securities</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter-2-dir/equity.html">Equity Securities</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter-2-dir/contracts.html">Derivative Securities</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../chapter-3-dir/chapter-3-landing.html">Unit 3. Portfolio Management</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../chapter-3-dir/data-markowitz.html">Data-Driven Portfolio Theory</a></li>
<li class="toctree-l2"><a class="reference internal" href="../chapter-3-dir/model-markowitz.html">Model-Driven Portfolio Theory</a></li>

<li class="toctree-l2"><a class="reference internal" href="../chapter-3-dir/hedged-portfolio.html">Hedged Portfolio Theory</a></li>

</ul>
</li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="chapter-4-landing.html">Unit 4. Financial Decisions</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul class="current">
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Markov Chains</a></li>

<li class="toctree-l2"><a class="reference internal" href="mdp.html">Stochastic Sequential Decision Making</a></li>

<li class="toctree-l2"><a class="reference internal" href="bandits.html">Multiarm Bandit Problems</a></li>

<li class="toctree-l2"><a class="reference internal" href="rl.html">Reinforcement Learning</a></li>

</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../appendix/appendix-landing.html">Appendices</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../appendix/random.html">Random variables and probability</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/julia-installation.html">Julia Installation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/julia-basics.html">Introduction to Julia Basics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../appendix/julia-data.html">Working with Data in Julia</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../References.html">References</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/varnerlab/CHEME-5660-Markets-Mayhem-Book" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/varnerlab/CHEME-5660-Markets-Mayhem-Book/issues/new?title=Issue%20on%20page%20%2Fchapter-4-dir/markov.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/chapter-4-dir/markov.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Markov Chains</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Markov Chains</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-time-markov-chains">Discrete-time Markov chains</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-the-stationary-distribution">Sampling the stationary distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-markov-models-hmms">Hidden Markov Models (HMMs)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="markov-chains">
<h1>Markov Chains<a class="headerlink" href="#markov-chains" title="Permalink to this headline">#</a></h1>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Andrey_Markov">Andrey Markov (1856 - 1922)</a> introduced Markov chains in the early 20th century. These mathematical models have found wide-ranging applications in fields such as finance, physics, biology, engineering, and computer science.</p>
<p>Markov chains are stochastic processes that model the probability of moving from one state to another in discrete time steps. The model assumes that the probability of transitioning from one state to another depends solely on the current state and not on any past events. Markov chains are particularly useful for modeling complex systems that involve uncertainty and randomness, including predicting weather patterns and the behavior of stock prices.</p>
<div class="topic">
<p class="topic-title">Outline</p>
<ul class="simple">
<li><p><a class="reference internal" href="#content-references-discrete-time-markov-chains"><span class="std std-ref">Discrete-time Markov chains</span></a> are mathematical models that describe the behavior of a system that transitions between a finite set of states at discrete time steps. The evolution of the system depends only on its current state and not on its previous history.</p></li>
<li><p><a class="reference internal" href="#content-references-structure-of-an-hmm"><span class="std std-ref">Hidden Markov Models (HMMs)</span></a> is a probabilistic model that describes a system where the observations are generated by an underlying Markov process whose states are not directly observable. The goal is to infer the hidden states given only the observations.</p></li>
</ul>
</div>
<hr class="docutils" />
<section id="discrete-time-markov-chains">
<span id="content-references-discrete-time-markov-chains"></span><h2>Discrete-time Markov chains<a class="headerlink" href="#discrete-time-markov-chains" title="Permalink to this headline">#</a></h2>
<figure class="align-default" id="fig-discrete-markov-model">
<a class="reference internal image-reference" href="../_images/Fig-Discrete-MarkovChain-Schematic.pdf"><img alt="../_images/Fig-Discrete-MarkovChain-Schematic.pdf" src="../_images/Fig-Discrete-MarkovChain-Schematic.pdf" style="height: 120px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 33 </span><span class="caption-text">Schematic of a discrete two-state time-invariant Markov model; <span class="math notranslate nohighlight">\(p_{ij}\)</span> denotes the time-invariant transition probability between state <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span>.</span><a class="headerlink" href="#fig-discrete-markov-model" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>A discrete-time Markov chain is a sequence of random variables <span class="math notranslate nohighlight">\(X_{1}\)</span>, <span class="math notranslate nohighlight">\(X_{2}\)</span>, <span class="math notranslate nohighlight">\(X_{3}\)</span>, …, <span class="math notranslate nohighlight">\(X_{n}\)</span> that have the <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_property">Markov property</a>, i.e., the probability of moving to the <em>next state</em> depends only on the <em>present state</em> and not on the <em>previous states</em>:</p>
<div class="math notranslate nohighlight" id="equation-eqn-markov-property">
<span class="eqno">(41)<a class="headerlink" href="#equation-eqn-markov-property" title="Permalink to this equation">#</a></span>\[P(X_{n+1} = x | X_{1}=x_{1}, \dots, X_{n}=x_{n}) = P(X_{n+1} = x | X_{n}=y)\]</div>
<p>where <em>states</em> refer to a finite set of discrete values in which the system can exist.  If the state space is finite, the transition probability distribution, i.e., the probability of moving from the state(s) <span class="math notranslate nohighlight">\(i\rightarrow{j}\)</span>, can be encoded in the transition matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>. Elements of <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>, denoted as <span class="math notranslate nohighlight">\(p_{ij}\)</span>, encode the probability of moving from state <span class="math notranslate nohighlight">\(i\rightarrow{j}\)</span> during the next time step:</p>
<div class="math notranslate nohighlight" id="equation-eqn-transition-prob-matrix">
<span class="eqno">(42)<a class="headerlink" href="#equation-eqn-transition-prob-matrix" title="Permalink to this equation">#</a></span>\[p_{ij} = P(X_{n+1}~=~j~|~X_{n}~=~i)\]</div>
<p>The transition matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> has interesting properties:</p>
<ul class="simple">
<li><p>First, the rows of transition matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> must sum to unity, i.e., each row encodes the probability of all possible outcomes. Thus, it must sum to one.</p></li>
<li><p>Second, if the transition matrix  <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is time-invariant, then <span class="math notranslate nohighlight">\(\mathbf{P}\)</span> is the same at each step, i.e., <span class="math notranslate nohighlight">\(p_{ij}\)</span> doesn’t change as <span class="math notranslate nohighlight">\(n\rightarrow{n+1}~\forall{n}\)</span>.</p></li>
</ul>
<p>Putting these ideas together gives (<a class="reference internal" href="#defn-n-transition">Definition 31</a>):</p>
<div class="proof definition admonition" id="defn-n-transition">
<p class="admonition-title"><span class="caption-number">Definition 31 </span> (Time-invariant state transition)</p>
<section class="definition-content" id="proof-content">
<p>A Markov chain has finite state set <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> and the time-invariant state transition matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>. Let the state vector at time <span class="math notranslate nohighlight">\(j\)</span> be given by <span class="math notranslate nohighlight">\(\mathbf{x}_{j}\)</span>, where <span class="math notranslate nohighlight">\(x_{s,j}\geq{0},\forall{s}\in\mathcal{S}\)</span> and:</p>
<div class="math notranslate nohighlight">
\[\sum_{s\in\mathcal{S}}x_{s,j} = 1\qquad\forall{j}\]</div>
<p>Then, the state of the Markov chain at time step <span class="math notranslate nohighlight">\(n+1\)</span> is given by:</p>
<div class="math notranslate nohighlight">
\[\mathbf{x}_{n+1} = \mathbf{x}_{n}\mathbf{P}^n\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{x}_{n}\)</span> denotes the system state vector at time step <span class="math notranslate nohighlight">\(n\)</span>.</p>
</section>
</div><p>Finally, suppose that a Markov chain is both time-invariant and non-periodic. Then, there exists a unique stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span> such that <span class="math notranslate nohighlight">\(\mathbf{P}^{k}\)</span> converges to a rank-one matrix in which each row is the stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span>:</p>
<div class="math notranslate nohighlight">
\[\lim_{k\rightarrow\infty} \mathbf{P}^{k} = \mathbf{1}\pi\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbf{1}\)</span> is a column vector of all 1’s. Let’s consider an example to make these ideas less abstract (<a class="reference internal" href="#example-dicrete-mchain">Example 26</a>):</p>
<div class="proof example dropdown admonition" id="example-dicrete-mchain">
<p class="admonition-title"><span class="caption-number">Example 26 </span> (Discrete Markov chain stationary distribution)</p>
<section class="example-content" id="proof-content">
<p>Consider the time-invariant two-state Discrete Markov chain with state transition matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{P} = \begin{bmatrix}
0.9 &amp; 0.1 \\
0.6 &amp; 0.4 \\
\end{bmatrix}
\end{split}\]</div>
<p>shown in (<a class="reference internal" href="#fig-discrete-markov-model"><span class="std std-numref">Fig. 33</span></a>). This transition matrix admits a stationary (non-periodic) solution. As the number of iterations <span class="math notranslate nohighlight">\(n\)</span> becomes large the system state converges to a stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span>. Thus, regardless of the starting state of this Markov chain, the long-term behavior is given by the stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span>.</p>
<p>Develop a script to compute the stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span>:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># load package -</span>
<span class="k">using</span> <span class="n">LinearAlgebra</span>

<span class="s">&quot;&quot;&quot;</span>
<span class="s">    iterate(P::Array{Float64,2}, counter::Int; </span>
<span class="s">        maxcount::Int = 100, ϵ::Float64 = 0.1) -&gt; Array{Float64,2}</span>

<span class="s">Recursively computes a stationary distribution. </span>
<span class="s">Computation stops if ||P_new - P|| &lt; ϵ or the max number of iterations is hit. </span>
<span class="s">&quot;&quot;&quot;</span>
<span class="k">function</span> <span class="n">iterate</span><span class="p">(</span><span class="n">P</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">2</span><span class="p">},</span> <span class="n">counter</span><span class="o">::</span><span class="kt">Int</span><span class="p">;</span> <span class="n">maxcount</span><span class="o">::</span><span class="kt">Int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="n">ϵ</span><span class="o">::</span><span class="kt">Float64</span> <span class="o">=</span> <span class="mf">0.1</span><span class="p">)</span><span class="o">::</span><span class="kt">Array</span><span class="p">{</span><span class="kt">Float64</span><span class="p">,</span><span class="mi">2</span><span class="p">}</span>

    <span class="c"># base case -</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">counter</span> <span class="o">==</span> <span class="n">maxcount</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">P</span>
    <span class="k">else</span>
        <span class="c"># generate a new P -</span>
        <span class="n">P_new</span> <span class="o">=</span> <span class="n">P</span><span class="o">^</span><span class="p">(</span><span class="n">counter</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">err</span> <span class="o">=</span> <span class="n">P_new</span> <span class="o">-</span> <span class="n">P</span><span class="p">;</span>
        <span class="k">if</span> <span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">err</span><span class="p">)</span><span class="o">&lt;=</span><span class="n">ϵ</span><span class="p">)</span>
            <span class="k">return</span> <span class="n">P_new</span>
        <span class="k">else</span>
            <span class="c"># we have NOT hit the error target, or the max iterations</span>
            <span class="n">iterate</span><span class="p">(</span><span class="n">P_new</span><span class="p">,</span> <span class="p">(</span><span class="n">counter</span><span class="o">+</span><span class="mi">1</span><span class="p">),</span> <span class="n">maxcount</span><span class="o">=</span><span class="n">maxcount</span><span class="p">,</span> <span class="n">ϵ</span> <span class="o">=</span> <span class="n">ϵ</span><span class="p">)</span>
        <span class="k">end</span>
    <span class="k">end</span>
<span class="k">end</span>

<span class="c"># Setup the transition probability matrix -</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mf">0.9</span> <span class="mf">0.1</span><span class="p">;</span>
    <span class="mf">0.6</span> <span class="mf">0.4</span><span class="p">;</span>
<span class="p">];</span>

<span class="c"># compute -</span>
<span class="n">counter</span> <span class="o">=</span> <span class="mi">1</span>
<span class="n">P_stationary</span> <span class="o">=</span> <span class="n">iterate</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="n">counter</span><span class="p">;</span>  <span class="n">maxcount</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">ϵ</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)</span>
</pre></div>
</div>
</section>
</div><section id="sampling-the-stationary-distribution">
<h3>Sampling the stationary distribution<a class="headerlink" href="#sampling-the-stationary-distribution" title="Permalink to this headline">#</a></h3>
<p>Once the stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span> of the Markov chain has been estimated, we can use it to generate samples from that chain.
For example, the stationary distribution for the two-state Markov chain in <a class="reference internal" href="#example-dicrete-mchain">Example 26</a> is given by:</p>
<div class="math notranslate nohighlight">
\[\pi = (0.857,0.143)\]</div>
<p>We model this system as a <a class="reference external" href="https://en.wikipedia.org/wiki/Categorical_distribution">Categorical distribution</a>. A categorical distribution is a discrete probability distribution that models the probability of a random variable taking on one of a finite set of possible outcomes:</p>
<div class="math notranslate nohighlight" id="equation-eqn-categorical-dist">
<span class="eqno">(43)<a class="headerlink" href="#equation-eqn-categorical-dist" title="Permalink to this equation">#</a></span>\[P(X = k) = \pi\left[k\right]\]</div>
<p>Sampling a categorical distribution constructed from the stationary distribution <span class="math notranslate nohighlight">\(\pi\)</span> will return the stationary
distribution (<a class="reference internal" href="#example-categorical-dist">Example 27</a>):</p>
<div class="proof example dropdown admonition" id="example-categorical-dist">
<p class="admonition-title"><span class="caption-number">Example 27 </span> (Categorical distribution)</p>
<section class="example-content" id="proof-content">
<p>Sample a categorical distribution constructed using the stationary distribution:</p>
<div class="math notranslate nohighlight">
\[\pi = (0.857,0.143)\]</div>
<p>Generate <span class="math notranslate nohighlight">\(N = 1000\)</span> samples and compute the fraction of state <code class="docutils literal notranslate"><span class="pre">1</span></code> and state <code class="docutils literal notranslate"><span class="pre">2</span></code>.</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># include -</span>
<span class="n">include</span><span class="p">(</span><span class="s">&quot;Include.jl&quot;</span><span class="p">)</span>

<span class="c"># setup -</span>
<span class="nb">π</span> <span class="o">=</span> <span class="p">[</span> <span class="mf">0.857</span><span class="p">,</span> <span class="mf">0.143</span><span class="p">];</span>
<span class="n">number_of_samples</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">;</span>

<span class="c"># build a categorical distribution </span>
<span class="n">d</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="nb">π</span><span class="p">);</span>

<span class="c"># sample -</span>
<span class="n">samples</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">number_of_samples</span><span class="p">)</span>

<span class="c"># how many 1&#39;s -</span>
<span class="n">number_of_1</span> <span class="o">=</span> <span class="n">findall</span><span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">1</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="n">length</span><span class="p">;</span>
<span class="n">number_of_2</span> <span class="o">=</span> <span class="n">findall</span><span class="p">(</span><span class="n">x</span><span class="o">-&gt;</span> <span class="n">x</span> <span class="o">==</span> <span class="mi">2</span><span class="p">,</span> <span class="n">samples</span><span class="p">)</span> <span class="o">|&gt;</span> <span class="n">length</span><span class="p">;</span>

<span class="c"># println -</span>
<span class="n">println</span><span class="p">(</span><span class="s">&quot;Fraction of state 1: </span><span class="si">$</span><span class="p">(</span><span class="n">number_of_1</span><span class="o">/</span><span class="n">number_of_samples</span><span class="p">)</span><span class="s"> and state 2: </span><span class="si">$</span><span class="p">(</span><span class="n">number_of_2</span><span class="o">/</span><span class="n">number_of_samples</span><span class="p">)</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</section>
</div></section>
</section>
<section id="hidden-markov-models-hmms">
<span id="content-references-structure-of-an-hmm"></span><h2>Hidden Markov Models (HMMs)<a class="headerlink" href="#hidden-markov-models-hmms" title="Permalink to this headline">#</a></h2>
<p>Hidden Markov models (HMMs) are statistical models in which the system being modeled is assumed to be a Markov process with unobservable states <span class="math notranslate nohighlight">\(s\in\mathcal{S}\)</span> but observable outcomes <span class="math notranslate nohighlight">\(o\in\mathcal{O}\)</span>. HMMs have the same structural components as a standard Markov chain model. However, each hidden state can be considered sending an observable single, with the emission probability.</p>
<figure class="align-default" id="fig-discrete-hidden-markov-model">
<a class="reference internal image-reference" href="../_images/Fig-HMM-Schematic-23.pdf"><img alt="../_images/Fig-HMM-Schematic-23.pdf" src="../_images/Fig-HMM-Schematic-23.pdf" style="height: 280px;" /></a>
<figcaption>
<p><span class="caption-number">Fig. 34 </span><span class="caption-text">Schematic of a discrete two-state time-invariant hidden Markov model (HMM); <span class="math notranslate nohighlight">\(p_{ij}\)</span> denotes the time-invariant transition probability between state <span class="math notranslate nohighlight">\(i\)</span> and <span class="math notranslate nohighlight">\(j\)</span> while <span class="math notranslate nohighlight">\(t_{ij}\)</span> denotes the emission probability for state <span class="math notranslate nohighlight">\(i\)</span> and observation <span class="math notranslate nohighlight">\(j\)</span>.</span><a class="headerlink" href="#fig-discrete-hidden-markov-model" title="Permalink to this image">#</a></p>
</figcaption>
</figure>
<p>The emission probability refers to the likelihood of observing a particular output <span class="math notranslate nohighlight">\(Y = o_{t}\)</span>, given the current state of the Markov chain <span class="math notranslate nohighlight">\(X = s_{t}\)</span>:</p>
<div class="math notranslate nohighlight" id="equation-eqn-hmm-output">
<span class="eqno">(44)<a class="headerlink" href="#equation-eqn-hmm-output" title="Permalink to this equation">#</a></span>\[P(Y = o_{t} | X = s_{t})\]</div>
<p>Similar to the transition probability, the emission probability must sum to unity:</p>
<div class="math notranslate nohighlight">
\[\sum_{o\in\mathcal{O}} P(Y = o | X = s) = 1\qquad\forall{s\in\mathcal{S}}\]</div>
<p>The emission probability plays a crucial role in HMMs, as it is used to calculate the likelihood of a sequence of observed symbols, given the current state of the hidden Markov chain. This likelihood is then used in various applications, including speech recognition, natural language processing, and bioinformatics. The emission probability can be computed using different methods, including maximum likelihood estimation or Bayesian inference.</p>
<p>Let’s build upon <a class="reference internal" href="#example-dicrete-mchain">Example 26</a> and construct an HMM that mimics a <a class="reference external" href="https://en.wikipedia.org/wiki/Trinomial_tree">trinomial lattice model of Boyle</a> (<a class="reference internal" href="#example-dicrete-mchain-hmm">Example 28</a>):</p>
<div class="proof example dropdown admonition" id="example-dicrete-mchain-hmm">
<p class="admonition-title"><span class="caption-number">Example 28 </span> (Stationary hidden Markov model)</p>
<section class="example-content" id="proof-content">
<p>Model the share price of a stock <code class="docutils literal notranslate"><span class="pre">XYZ</span></code> using a time-invariant two-state Discrete Markov chain with the state transition matrix <span class="math notranslate nohighlight">\(\mathbf{P}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{P} = \begin{bmatrix}
0.60 &amp; 0.40 \\
0.35 &amp; 0.65 \\
\end{bmatrix}
\end{split}\]</div>
<p>and an emission probability matrix <span class="math notranslate nohighlight">\(\mathbf{E}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{E} = \begin{bmatrix}
0.70 &amp; 0.20 &amp; 0.1 \\
0.10 &amp; 0.20 &amp; 0.7 \\
\end{bmatrix}
\end{split}\]</div>
<p>Let <span class="math notranslate nohighlight">\(Y_{i}\)</span> denote the observable value for state <span class="math notranslate nohighlight">\(i\)</span>. Assume output state <code class="docutils literal notranslate"><span class="pre">1</span></code> is an up move (a 1% increase), state <code class="docutils literal notranslate"><span class="pre">2</span></code> the price stays the same, and state <code class="docutils literal notranslate"><span class="pre">3</span></code> indicates a price drop (a 1% decrease).</p>
<p>Simulation script:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># include the include -</span>
<span class="n">include</span><span class="p">(</span><span class="s">&quot;Include.jl&quot;</span><span class="p">);</span> <span class="c"># load paths, packages and codes</span>

<span class="c"># PHASE 1: Setup the calculation</span>
<span class="c"># Setup/initialize</span>
<span class="n">number_of_hidden_states</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">number_of_output_states</span> <span class="o">=</span> <span class="mi">3</span>
<span class="n">number_of_simulation_steps</span> <span class="o">=</span> <span class="mi">480</span>
<span class="n">emission_probability_dict</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">{</span><span class="kt">Int</span><span class="p">,</span><span class="kt">Categorical</span><span class="p">}()</span>
<span class="n">simulation_dict</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">{</span><span class="kt">Int</span><span class="p">,</span><span class="kt">Int</span><span class="p">}()</span>

<span class="c"># Transition matrix for the MC</span>
<span class="n">P</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mf">0.60</span> <span class="mf">0.40</span><span class="p">;</span>
    <span class="mf">0.35</span> <span class="mf">0.65</span><span class="p">;</span>
<span class="p">];</span>

<span class="c"># Emission probability matrix -</span>
<span class="n">EPM</span> <span class="o">=</span> <span class="p">[</span>
    <span class="mf">0.70</span> <span class="mf">0.20</span> <span class="mf">0.1</span> <span class="p">;</span>
    <span class="mf">0.10</span> <span class="mf">0.20</span> <span class="mf">0.7</span> <span class="p">;</span>
<span class="p">]</span>

<span class="c"># compute the stationary distribution for the MC -</span>
<span class="nb">π</span> <span class="o">=</span> <span class="n">iterate</span><span class="p">(</span><span class="n">P</span><span class="p">,</span> <span class="mi">1</span><span class="p">;</span>  <span class="n">maxcount</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="n">ϵ</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">)[</span><span class="mi">1</span><span class="p">,</span><span class="o">:</span><span class="p">]</span> <span class="c"># assumption: iterate converges</span>
<span class="n">mcd</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="nb">π</span><span class="p">);</span> <span class="c"># Markov-chain distribution</span>

<span class="c"># construct emission probability dictionary -</span>
<span class="k">for</span> <span class="n">i</span> <span class="o">∈</span> <span class="mi">1</span><span class="o">:</span><span class="n">number_of_hidden_states</span>
    <span class="n">emission_probability_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">EPM</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="o">:</span><span class="p">])</span>
<span class="k">end</span>

<span class="c"># PHASE 2: Simulation </span>
<span class="k">for</span> <span class="n">i</span> <span class="o">∈</span> <span class="mi">1</span><span class="o">:</span><span class="n">number_of_simulation_steps</span>
    
    <span class="c"># which state is the mc in?</span>
    <span class="n">hidden_state</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">mcd</span><span class="p">);</span>
    
    <span class="c"># grab the emission probability model from the emission_probability_dict -</span>
    <span class="n">epd</span> <span class="o">=</span> <span class="n">emission_probability_dict</span><span class="p">[</span><span class="n">hidden_state</span><span class="p">];</span>
    
    <span class="c"># role for a random ouput -</span>
    <span class="n">simulation_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">epd</span><span class="p">);</span>
<span class="k">end</span>
</pre></div>
</div>
<p>Plotting script:</p>
<div class="highlight-julia notranslate"><div class="highlight"><pre><span></span><span class="c"># runme -</span>
<span class="n">include</span><span class="p">(</span><span class="s">&quot;runme.jl&quot;</span><span class="p">)</span> <span class="c"># loads packages, computes simulation_dict -</span>

<span class="c"># Setup -</span>
<span class="n">Sₒ</span> <span class="o">=</span> <span class="mf">100.0</span><span class="p">;</span>
<span class="n">Δ</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.01</span><span class="p">,</span> <span class="mf">0.0</span><span class="p">,</span> <span class="o">-</span><span class="mf">0.01</span><span class="p">];</span>
<span class="n">S</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">{</span><span class="kt">Int</span><span class="p">,</span><span class="kt">Float64</span><span class="p">}()</span>
<span class="n">S</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">Sₒ</span>

<span class="c"># setup colors -</span>
<span class="n">colors</span> <span class="o">=</span> <span class="kt">Dict</span><span class="p">{</span><span class="kt">Int</span><span class="p">,</span><span class="kt">RGB</span><span class="p">}();</span>
<span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="sa">colorant</span><span class="s">&quot;#0077BB&quot;</span>

<span class="c"># sim loop -</span>
<span class="k">for</span> <span class="n">i</span> <span class="o">∈</span> <span class="mi">1</span><span class="o">:</span><span class="n">number_of_simulation_steps</span>

    <span class="c"># market state -</span>
    <span class="n">market_state_index</span> <span class="o">=</span> <span class="n">simulation_dict</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>

    <span class="c"># get previous price -</span>
    <span class="n">S_old</span> <span class="o">=</span> <span class="n">S</span><span class="p">[</span><span class="n">i</span><span class="o">-</span><span class="mi">1</span><span class="p">];</span>
    <span class="n">S</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">S_old</span><span class="o">*</span><span class="n">exp</span><span class="p">(</span><span class="n">Δ</span><span class="p">[</span><span class="n">market_state_index</span><span class="p">]);</span>
<span class="k">end</span>

<span class="c"># make a plot -</span>
<span class="n">plot!</span><span class="p">(</span><span class="n">S</span><span class="p">,</span><span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span><span class="n">c</span><span class="o">=</span><span class="n">colors</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span><span class="n">label</span><span class="o">=</span><span class="s">&quot;&quot;</span><span class="p">)</span>
<span class="n">xlabel!</span><span class="p">(</span><span class="s">&quot;Time index (AU)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
<span class="n">ylabel!</span><span class="p">(</span><span class="s">&quot;Share price (USD/share)&quot;</span><span class="p">,</span> <span class="n">fontsize</span><span class="o">=</span><span class="mi">18</span><span class="p">)</span>
</pre></div>
</div>
</section>
</div></section>
</section>
<hr class="docutils" />
<section class="tex2jax_ignore mathjax_ignore" id="summary">
<h1>Summary<a class="headerlink" href="#summary" title="Permalink to this headline">#</a></h1>
<p>In this lecture, we discussed Markov models:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#content-references-discrete-time-markov-chains"><span class="std std-ref">Discrete-time Markov chains</span></a> are mathematical models that describe the behavior of a system that transitions between a finite set of states at discrete time steps. The evolution of the system depends only on its current state and not on its previous history.</p></li>
<li><p><a class="reference internal" href="#content-references-structure-of-an-hmm"><span class="std std-ref">Hidden Markov Models (HMMs)</span></a> is a probabilistic model that describes a system where the observations are generated by an underlying Markov process whose states are not directly observable. The goal is to infer the hidden states given only the observations.</p></li>
</ul>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./chapter-4-dir"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="chapter-4-landing.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Unit 4: Decisions</p>
      </div>
    </a>
    <a class="right-next"
       href="mdp.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Stochastic Sequential Decision Making</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Markov Chains</a><ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-time-markov-chains">Discrete-time Markov chains</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sampling-the-stationary-distribution">Sampling the stationary distribution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#hidden-markov-models-hmms">Hidden Markov Models (HMMs)</a></li>
</ul>
</li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#summary">Summary</a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Varner and Woltornist
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      © Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>